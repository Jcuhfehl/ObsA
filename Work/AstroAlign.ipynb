{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning the science exposures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To align the science exposures and remove the shifts seen in a previous exercise we use the AstroAlign package.\n",
    "AstroAlign looks for 3-point asterisms (i.e., triangles of stars) in pairs of images and computes a linear transformation based on matching asterisms.\n",
    "\n",
    "We import the package as aa, and we will also need astropy.io.fits to read fits files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astroalign as aa\n",
    "import astropy.io.fits as fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read the reference (\"target\") image and the image to be transformed (\"source\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatarg = fits.getdata('science1Vf.fits')\n",
    "datasrc = fits.getdata('science10Vf.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the transformation from the source to the target frame requires only a single call to find_transform():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, (source_pos_array, target_pos_array) = aa.find_transform(datasrc, datatarg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object T has attributes that contain information about the rotation, translation, and scaling of the transformation (T.rotation, T.translation, and T.scale). For a sequence of consecutive observations, we expect the rotation to be close to 0 and the scale should be close to 1 for any pair of observations obtained with the same instrument (no scale change). We do expect shifts (translations) due to inaccurate tracking. Let us check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(T.rotation*180/math.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, the scale and rotation are indeed small. To get an idea about what is acceptable, we recall that the longest dimension of the CCD image is 2184 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatarg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the rotation corresponds to a shift of much less than one pixel from one side of the CCD to the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatarg.shape[1] * T.rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check the shift, which may be larger (e.g. due to guiding / tracking errors). This is what we need to correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T.translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source_pos_array and target_pos_array variables are lists of the coordinates of the sources used by astroalign to define the transformation.  Let us plot them on top of the image to check that astroalign has made a sensible choice of stars to use for the transformation.\n",
    "\n",
    "First, we transpose the target_pos_array to two individual arrays containing the x and y coordinates. This is because the coordinates are stored as an array of [x, y] pairs in target_pos_array, whereas we need the x and y in separate arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_pos_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, doing the conversion is easy. We just use the transpose() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = target_pos_array.transpose()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the coordinates of the stars used by AstroAlign on top of the target image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(datatarg, vmin=500, vmax=1500, cmap='magma')\n",
    "plt.plot(x, y, 'wo', fillstyle='none', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems OK, so we go ahead and apply the transformation to the source image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tran, footprint = aa.apply_transform(T, datasrc, datatarg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then write the result to an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.writeto('science10Vft.fits', data_tran, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final test of whether the transformation went well is to blink the two images against each other. We can do this in DS9. Let us see how we can do all of this via the imexam interface. First we set up a viewer interface and load the reference image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imexam\n",
    "viewer = imexam.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.load_fits('science1Vf.fits')\n",
    "viewer.scale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we open a second frame in DS9 and load the transformed source image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.frame(2)\n",
    "viewer.load_fits('science10Vft.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we blink the two frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.blink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, any shifts will now have disappeared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If it fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occasionally, the procedure described above may randomly fail if an insufficient number of stars are identified and used for the transformation.\n",
    "\n",
    "It is therefore extremely important to check that the rotation and scale change are within acceptable limits. \n",
    "If this is not the case, then the first thing to try is to just call find_transform() again. \n",
    "\n",
    "If the problem persists and find_transform() is unable to find an acceptable transformation after repeated attempts, an alternative solution is to manually define a list of reference coordinates. This can then be passed to find_transform() instead of the images. The rest of the procedure works as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how a transformation can be defined using the coodinates of stars in science1V.FIT and science10V.FIT that we measured earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "coo_targ = np.loadtxt('coo1V.txt', usecols=(0,1))\n",
    "coo_src  = np.loadtxt('coo10V.txt', usecols=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, (source_pos_array, target_pos_array) = aa.find_transform(coo_src, coo_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T.scale, T.rotation, T.translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare the shifts determined by find_transform() with those determined in Assignment 4.1\n",
    "\n",
    "In order to get a reliable transformation, it is important to select stars that are distributed across the image, so that the scale and rotation are well constrained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
